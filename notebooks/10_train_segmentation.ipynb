{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Training: U-Net for Lesion Segmentation\n",
    "\n",
    "**Goals:**\n",
    "- Train U-Net (ResNet-34 encoder) with 5-fold CV\n",
    "- Optimize Dice+BCE loss\n",
    "- Track metrics: Dice, IoU, Boundary F1\n",
    "- Save best checkpoints per fold\n",
    "- Aggregate results and report mean ± std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theomoura/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils import seed_everything\n",
    "from src.datamodules.bus_uc import BusUcSegDataModule\n",
    "from src.models.seg_unet import UNetRes34, LightningSegModel\n",
    "from src.losses import DiceBCELoss\n",
    "from src.metrics import dice_score, iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  task: segmentation\n",
      "  model: unet_res34\n",
      "  data_dir: BUS_UC/BUS_UC/BUS_UC\n",
      "  img_size: 256\n",
      "  in_channels: 3\n",
      "  encoder_name: resnet34\n",
      "  encoder_weights: imagenet\n",
      "  num_classes: 1\n",
      "  optimizer: adamw\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  scheduler: cosine\n",
      "  epochs: 100\n",
      "  early_stop_patience: 10\n",
      "  batch_size: 16\n",
      "  num_workers: 4\n",
      "  loss: {'name': 'dice_bce', 'dice_weight': 0.5, 'bce_weight': 0.5}\n",
      "  augment: medium\n",
      "  kfolds: 3\n",
      "  seed: 42\n",
      "  metrics: ['dice', 'iou', 'boundary_f1']\n",
      "  mixed_precision: True\n",
      "  gradient_clip: 1.0\n",
      "  save_best_by: dice\n",
      "  use_swa: False\n",
      "  swa_start_epoch: 95\n"
     ]
    }
   ],
   "source": [
    "# Load config from ../configs/seg_unet.yaml\n",
    "config = yaml.safe_load(open('../configs/seg_unet.yaml'))\n",
    "print(\"Configuration loaded:\")\n",
    "for key, val in config.items():\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 648\n",
      "Val samples: 163\n",
      "Test samples: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theomoura/Documents/coding/university/xai/bus-uc-breast-ultrasound/notebooks/../src/transforms/ultrasound.py:32: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(alpha=10, sigma=4, alpha_affine=0, p=elastic_p),\n",
      "/Users/theomoura/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m train_loader = datamodule.train_dataloader()\n\u001b[32m     21\u001b[39m batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m images, masks = batch[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, figsize=(\u001b[32m16\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m):\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Original image\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'mask'"
     ]
    }
   ],
   "source": [
    "# Initialize DataModule for fold 0\n",
    "seed_everything(42)\n",
    "\n",
    "datamodule = BusUcSegDataModule(\n",
    "    data_dir=config['data_dir'],\n",
    "    img_size=config['img_size'],\n",
    "    batch_size=config['batch_size'],\n",
    "    augment_level=config['augment'],\n",
    "    fold=0,\n",
    "    n_folds=config['kfolds'],\n",
    "    seed=config['seed']\n",
    ")\n",
    "datamodule.setup()\n",
    "\n",
    "print(f\"Train samples: {len(datamodule.train_dataset)}\")\n",
    "print(f\"Val samples: {len(datamodule.val_dataset)}\")\n",
    "print(f\"Test samples: {len(datamodule.test_dataset)}\")\n",
    "\n",
    "# Visualize batch\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "images, masks = batch['image'], batch['mask']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i in range(4):\n",
    "    # Original image\n",
    "    img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "    \n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f\"Image {i}\")\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Mask overlay\n",
    "    mask = masks[i, 0].cpu().numpy()\n",
    "    axes[1, i].imshow(img)\n",
    "    axes[1, i].imshow(mask, alpha=0.5, cmap='Reds')\n",
    "    axes[1, i].set_title(f\"Mask {i}\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Data visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize U-Net model\n",
    "backbone = UNetRes34(\n",
    "    num_classes=1,\n",
    "    encoder_name='resnet34',\n",
    "    encoder_weights='imagenet'\n",
    ")\n",
    "\n",
    "loss_fn = DiceBCELoss(\n",
    "    dice_weight=config['loss'].get('dice_weight', 0.5),\n",
    "    bce_weight=config['loss'].get('bce_weight', 0.5)\n",
    ")\n",
    "\n",
    "lightning_model = LightningSegModel(\n",
    "    model=backbone,\n",
    "    loss_fn=loss_fn,\n",
    "    learning_rate=config['lr'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    scheduler=config['scheduler'],\n",
    "    epochs=config['epochs']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(f\"Model: {config['model']}\")\n",
    "print(f\"Loss: {config['loss']['name']}\")\n",
    "print(f\"Learning rate: {config['lr']}\")\n",
    "print(f\"Epochs: {config['epochs']}\")\n",
    "print(f\"Batch size: {config['batch_size']}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in backbone.parameters())\n",
    "trainable_params = sum(p.numel() for p in backbone.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training (Single Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Trainer with callbacks\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='../outputs/seg_unet_fold0',\n",
    "    filename='best',\n",
    "    monitor='val_dice',\n",
    "    mode='max',\n",
    "    save_top_k=1\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_dice',\n",
    "    patience=config['early_stop_patience'],\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "logger = CSVLogger(save_dir='../outputs', name='seg_unet_fold0')\n",
    "\n",
    "# Train\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=config['epochs'],\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    precision='16-mixed' if config['mixed_precision'] else 32,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "    logger=logger,\n",
    "    gradient_clip_val=1.0,\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.fit(lightning_model, datamodule=datamodule)\n",
    "print(\"✓ Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint and evaluate on test set\n",
    "test_results = trainer.test(ckpt_path='best', datamodule=datamodule)\n",
    "print(\"\\nTest Results:\")\n",
    "for key, val in test_results[0].items():\n",
    "    print(f\"  {key}: {val:.4f}\")\n",
    "\n",
    "# Visualize predictions\n",
    "test_loader = datamodule.test_dataloader()\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "lightning_model.eval()\n",
    "with torch.no_grad():\n",
    "    images = batch['image']\n",
    "    masks_gt = batch['mask']\n",
    "    masks_pred = torch.sigmoid(lightning_model(images))\n",
    "\n",
    "# Plot examples\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "for i in range(4):\n",
    "    img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    \n",
    "    mask_gt = masks_gt[i, 0].cpu().numpy()\n",
    "    mask_pred = (masks_pred[i, 0].cpu().numpy() > 0.5).astype(float)\n",
    "    \n",
    "    # Image\n",
    "    axes[i, 0].imshow(img)\n",
    "    axes[i, 0].set_title('Input')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # GT mask\n",
    "    axes[i, 1].imshow(mask_gt, cmap='Reds')\n",
    "    axes[i, 1].set_title('Ground Truth')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Predicted mask\n",
    "    axes[i, 2].imshow(mask_pred, cmap='Reds')\n",
    "    axes[i, 2].set_title('Predicted')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[i, 3].imshow(img)\n",
    "    axes[i, 3].imshow(mask_pred, alpha=0.5, cmap='Reds')\n",
    "    axes[i, 3].set_title('Overlay')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation (All Folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for all 5 folds\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "for fold in range(config['kfolds']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Fold {fold}/{config['kfolds']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Seed\n",
    "    seed_everything(config['seed'] + fold)\n",
    "    \n",
    "    # DataModule\n",
    "    dm = BusUcSegDataModule(\n",
    "        data_dir=config['data_dir'],\n",
    "        img_size=config['img_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        augment_level=config['augment'],\n",
    "        fold=fold,\n",
    "        n_folds=config['kfolds'],\n",
    "        seed=config['seed']\n",
    "    )\n",
    "    dm.setup()\n",
    "    \n",
    "    # Model\n",
    "    bb = UNetRes34(num_classes=1, encoder_name='resnet34', encoder_weights='imagenet')\n",
    "    loss = DiceBCELoss(dice_weight=0.5, bce_weight=0.5)\n",
    "    model = LightningSegModel(\n",
    "        model=bb, loss_fn=loss, learning_rate=config['lr'],\n",
    "        weight_decay=config['weight_decay'], scheduler=config['scheduler'],\n",
    "        epochs=config['epochs']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    ckpt_cb = ModelCheckpoint(\n",
    "        dirpath=f'../outputs/seg_unet/fold_{fold}',\n",
    "        filename='best', monitor='val_dice', mode='max', save_top_k=1\n",
    "    )\n",
    "    early_cb = EarlyStopping(monitor='val_dice', patience=config['early_stop_patience'], mode='max')\n",
    "    lr_cb = LearningRateMonitor(logging_interval='epoch')\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['epochs'],\n",
    "        accelerator='auto', devices=1,\n",
    "        precision='16-mixed' if config['mixed_precision'] else 32,\n",
    "        callbacks=[ckpt_cb, early_cb, lr_cb],\n",
    "        logger=CSVLogger(save_dir='../outputs/seg_unet', name=f'fold_{fold}'),\n",
    "        gradient_clip_val=1.0, deterministic=True,\n",
    "        enable_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "    \n",
    "    # Test\n",
    "    test_res = trainer.test(ckpt_path='best', datamodule=dm)\n",
    "    results.append(test_res[0])\n",
    "    \n",
    "    # Save fold metrics\n",
    "    metrics_path = Path(f'../outputs/seg_unet/fold_{fold}/metrics.json')\n",
    "    metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(test_res[0], f, indent=2)\n",
    "    \n",
    "    print(f\"Fold {fold} complete: Dice={test_res[0]['test_dice']:.4f}\")\n",
    "\n",
    "# Aggregate results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Cross-Validation Results Summary\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "aggregated = {}\n",
    "metric_keys = results[0].keys()\n",
    "\n",
    "for key in metric_keys:\n",
    "    values = [r[key] for r in results]\n",
    "    aggregated[f'{key}_mean'] = float(np.mean(values))\n",
    "    aggregated[f'{key}_std'] = float(np.std(values))\n",
    "    print(f\"{key:20s}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# Save aggregated results\n",
    "agg_path = Path('../outputs/seg_unet/cv_results.json')\n",
    "with open(agg_path, 'w') as f:\n",
    "    json.dump(aggregated, f, indent=2)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Results saved to {agg_path}\")\n",
    "print(\"✓ Cross-validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze failure cases\n",
    "# Load best model from fold 0\n",
    "best_model_path = '../outputs/seg_unet/fold_0/best.ckpt'\n",
    "model = LightningSegModel.load_from_checkpoint(best_model_path)\n",
    "model.eval()\n",
    "\n",
    "# Get test set\n",
    "dm = BusUcSegDataModule(\n",
    "    data_dir=config['data_dir'],\n",
    "    img_size=config['img_size'],\n",
    "    batch_size=1,\n",
    "    augment_level='none',\n",
    "    fold=0,\n",
    "    n_folds=config['kfolds'],\n",
    "    seed=config['seed']\n",
    ")\n",
    "dm.setup()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "# Compute Dice for each sample\n",
    "dice_scores = []\n",
    "samples = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        img = batch['image']\n",
    "        mask_gt = batch['mask']\n",
    "        mask_pred = torch.sigmoid(model(img))\n",
    "        \n",
    "        dice = dice_score(mask_pred, mask_gt)\n",
    "        dice_scores.append(dice.item())\n",
    "        samples.append((img, mask_gt, mask_pred))\n",
    "\n",
    "# Find worst predictions\n",
    "worst_indices = np.argsort(dice_scores)[:5]\n",
    "\n",
    "# Visualize failures\n",
    "fig, axes = plt.subplots(5, 4, figsize=(16, 20))\n",
    "for row, idx in enumerate(worst_indices):\n",
    "    img, mask_gt, mask_pred = samples[idx]\n",
    "    \n",
    "    img_np = img[0].permute(1, 2, 0).cpu().numpy()\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    \n",
    "    mask_gt_np = mask_gt[0, 0].cpu().numpy()\n",
    "    mask_pred_np = (mask_pred[0, 0].cpu().numpy() > 0.5).astype(float)\n",
    "    \n",
    "    # Image\n",
    "    axes[row, 0].imshow(img_np)\n",
    "    axes[row, 0].set_title(f'Dice={dice_scores[idx]:.3f}')\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    # GT\n",
    "    axes[row, 1].imshow(mask_gt_np, cmap='Reds')\n",
    "    axes[row, 1].set_title('GT')\n",
    "    axes[row, 1].axis('off')\n",
    "    \n",
    "    # Pred\n",
    "    axes[row, 2].imshow(mask_pred_np, cmap='Reds')\n",
    "    axes[row, 2].set_title('Predicted')\n",
    "    axes[row, 2].axis('off')\n",
    "    \n",
    "    # Overlay difference\n",
    "    axes[row, 3].imshow(img_np)\n",
    "    # Green = GT only, Red = Pred only, Yellow = Both\n",
    "    diff = np.zeros((*mask_gt_np.shape, 3))\n",
    "    diff[..., 1] = mask_gt_np  # GT in green channel\n",
    "    diff[..., 0] = mask_pred_np  # Pred in red channel\n",
    "    axes[row, 3].imshow(diff, alpha=0.5)\n",
    "    axes[row, 3].set_title('GT(G) vs Pred(R)')\n",
    "    axes[row, 3].axis('off')\n",
    "\n",
    "plt.suptitle('Top 5 Failure Cases', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Worst Dice: {min(dice_scores):.4f}\")\n",
    "print(f\"Best Dice: {max(dice_scores):.4f}\")\n",
    "print(f\"Mean Dice: {np.mean(dice_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "# Print final results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SEGMENTATION RESULTS (5-Fold CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load aggregated results\n",
    "with open('../outputs/seg_unet/cv_results.json', 'r') as f:\n",
    "    agg = json.load(f)\n",
    "\n",
    "print(f\"\\nMean Dice:        {agg['test_dice_mean']:.4f} ± {agg['test_dice_std']:.4f}\")\n",
    "print(f\"Mean IoU:         {agg['test_iou_mean']:.4f} ± {agg['test_iou_std']:.4f}\")\n",
    "if 'test_boundary_f1_mean' in agg:\n",
    "    print(f\"Mean Boundary F1: {agg['test_boundary_f1_mean']:.4f} ± {agg['test_boundary_f1_std']:.4f}\")\n",
    "\n",
    "# Quality gate check\n",
    "dice_mean = agg['test_dice_mean']\n",
    "quality_gate_dice = 0.80\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Quality Gate Check:\")\n",
    "print(f\"  Target: Dice ≥ {quality_gate_dice}\")\n",
    "print(f\"  Achieved: {dice_mean:.4f}\")\n",
    "\n",
    "if dice_mean >= quality_gate_dice:\n",
    "    print(\"  Status: ✓ PASSED\")\n",
    "else:\n",
    "    print(f\"  Status: ✗ FAILED (gap: {quality_gate_dice - dice_mean:.4f})\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
